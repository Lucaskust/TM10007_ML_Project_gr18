{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "546b66e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:18: SyntaxWarning: invalid escape sequence '\\T'\n",
      "<>:18: SyntaxWarning: invalid escape sequence '\\T'\n",
      "C:\\Users\\jelle\\AppData\\Local\\Temp\\ipykernel_21808\\4280346610.py:18: SyntaxWarning: invalid escape sequence '\\T'\n",
      "  data = pd.read_excel(\"..\\TrainData.xlsx\")\n",
      "C:\\Users\\jelle\\AppData\\Local\\Temp\\ipykernel_21808\\4280346610.py:18: SyntaxWarning: invalid escape sequence '\\T'\n",
      "  data = pd.read_excel(\"..\\TrainData.xlsx\")\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '..\\\\TrainData.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipeline\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Pipeline\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# 🧾 Stap 1 – Laad de data\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mTrainData.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# 🔍 Eerste inspectie\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVorm van de data:\u001b[39m\u001b[38;5;124m\"\u001b[39m, data\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[1;32mc:\\Users\\jelle\\OneDrive - Delft University of Technology\\10007 Machine learning\\.conda\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:495\u001b[0m, in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[0;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[0;32m    494\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 495\u001b[0m     io \u001b[38;5;241m=\u001b[39m ExcelFile(\n\u001b[0;32m    496\u001b[0m         io,\n\u001b[0;32m    497\u001b[0m         storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m    498\u001b[0m         engine\u001b[38;5;241m=\u001b[39mengine,\n\u001b[0;32m    499\u001b[0m         engine_kwargs\u001b[38;5;241m=\u001b[39mengine_kwargs,\n\u001b[0;32m    500\u001b[0m     )\n\u001b[0;32m    501\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[0;32m    502\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    503\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    504\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    505\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\jelle\\OneDrive - Delft University of Technology\\10007 Machine learning\\.conda\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1550\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m   1548\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxls\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1549\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1550\u001b[0m     ext \u001b[38;5;241m=\u001b[39m inspect_excel_format(\n\u001b[0;32m   1551\u001b[0m         content_or_path\u001b[38;5;241m=\u001b[39mpath_or_buffer, storage_options\u001b[38;5;241m=\u001b[39mstorage_options\n\u001b[0;32m   1552\u001b[0m     )\n\u001b[0;32m   1553\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1554\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1555\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExcel file format cannot be determined, you must specify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1556\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man engine manually.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1557\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\jelle\\OneDrive - Delft University of Technology\\10007 Machine learning\\.conda\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1402\u001b[0m, in \u001b[0;36minspect_excel_format\u001b[1;34m(content_or_path, storage_options)\u001b[0m\n\u001b[0;32m   1399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content_or_path, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[0;32m   1400\u001b[0m     content_or_path \u001b[38;5;241m=\u001b[39m BytesIO(content_or_path)\n\u001b[1;32m-> 1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[0;32m   1403\u001b[0m     content_or_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m, storage_options\u001b[38;5;241m=\u001b[39mstorage_options, is_text\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1404\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[0;32m   1405\u001b[0m     stream \u001b[38;5;241m=\u001b[39m handle\u001b[38;5;241m.\u001b[39mhandle\n\u001b[0;32m   1406\u001b[0m     stream\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\jelle\\OneDrive - Delft University of Technology\\10007 Machine learning\\.conda\\Lib\\site-packages\\pandas\\io\\common.py:882\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n\u001b[0;32m    883\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[0;32m    885\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '..\\\\TrainData.xlsx'"
     ]
    }
   ],
   "source": [
    "# 📦 Vereiste imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, chi2, RFECV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split, cross_validate, GridSearchCV\n",
    "from sklearn.metrics import make_scorer, accuracy_score, f1_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# 🧾 Stap 1 – Laad de data\n",
    "data = pd.read_excel(\"..\\TrainData.xlsx\")\n",
    "\n",
    "# 🔍 Eerste inspectie\n",
    "print(\"Vorm van de data:\", data.shape)\n",
    "print(\"Kolommen:\", data.columns.tolist())\n",
    "print(\"Aantal duplicaten:\", data.duplicated().sum())\n",
    "print(\"Missende waarden per kolom:\")\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# 🧼 Stap 2 – Dubbele rijen verwijderen\n",
    "data = data.drop_duplicates()\n",
    "\n",
    "# 🎯 Stap 3 – Split in features en labels\n",
    "X = data.drop(columns=\"label\")\n",
    "y = data[\"label\"]\n",
    "\n",
    "# 🔁 Zet y om naar numeriek met behoud van pandas Series\n",
    "label_encoder = LabelEncoder()\n",
    "y = pd.Series(label_encoder.fit_transform(y), index=y.index)\n",
    "\n",
    "# ❓ Hoeveel missende waarden blijven over?\n",
    "print(\"Totaal aantal missende waarden:\", X.isnull().sum().sum())\n",
    "\n",
    "# ⚠️ Stap 4 – NaNs imputer (mediaan)\n",
    "X = X.fillna(X.median(numeric_only=True))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645d87f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script implements two machine learning pipelines using the Naive Bayes classifier. \n",
    "# The goal is to preprocess the data, perform feature selection, and optimize hyperparameters \n",
    "# using grid search with cross-validation. Two different scaling methods (MinMaxScaler and \n",
    "# StandardScaler) are applied to compare their effects on model performance. The results of \n",
    "# the grid search, including the best hyperparameters, are saved to Excel files for further analysis.\n",
    "\n",
    "# Pipeline 1\n",
    "\n",
    "# Initialize MinMaxScaler to scale features to a range between 0 and 1\n",
    "scaler_minmax = MinMaxScaler()\n",
    "X_Scaled = scaler_minmax.fit_transform(X)  # Apply scaling to the feature set X\n",
    "\n",
    "# Initialize Gaussian Naive Bayes classifier\n",
    "gaussian = GaussianNB()\n",
    "\n",
    "# Create a pipeline with feature selection and classifier\n",
    "pipeline = Pipeline([\n",
    "    ('feature_selection', SelectKBest(chi2)),  # Select top features based on chi-squared test\n",
    "    ('classifier', gaussian)  # Use Gaussian Naive Bayes as the classifier\n",
    "])\n",
    "\n",
    "# Define grid search parameters for hyperparameter tuning\n",
    "Grid_params = {\n",
    "    'feature_selection__k': [80, 100, 120, 130, 140],  # Number of top features to select\n",
    "    'classifier__var_smoothing': [1, 0.1, 0.01, 0.001]  # Smoothing parameter for Naive Bayes\n",
    "}\n",
    "\n",
    "# Perform grid search with 5-fold cross-validation and ROC AUC scoring\n",
    "grid_search = GridSearchCV(pipeline, param_grid=Grid_params, cv=StratifiedKFold(5), scoring='roc_auc', n_jobs=-1)\n",
    "grid_search.fit(X_Scaled, y)  # Fit the grid search to the scaled data and labels\n",
    "\n",
    "# Save the grid search results to a DataFrame\n",
    "results_df = pd.DataFrame(grid_search.cv_results_)\n",
    "\n",
    "# Export the results to an Excel file\n",
    "results_df.to_excel(\"grid_search_Naive_bayes_results_chi.xlsx\", index=False)\n",
    "\n",
    "# Print the best parameters found during grid search\n",
    "print(\"Beste parameters:\", grid_search.best_params_)\n",
    "\n",
    "\n",
    "# Pipeline 2\n",
    "\n",
    "# Initialize StandardScaler to standardize features by removing the mean and scaling to unit variance\n",
    "scaler_standard = StandardScaler()\n",
    "X_Scaled = scaler_standard.fit_transform(X)  # Apply scaling to the feature set X\n",
    "\n",
    "# Initialize Gaussian Naive Bayes classifier\n",
    "gaussian = GaussianNB()\n",
    "\n",
    "# Create a pipeline with feature selection and classifier\n",
    "pipeline = Pipeline([\n",
    "    ('feature_selection', SelectKBest()),  # Select top features (default scoring method)\n",
    "    ('classifier', gaussian)  # Use Gaussian Naive Bayes as the classifier\n",
    "])\n",
    "\n",
    "# Define grid search parameters for hyperparameter tuning\n",
    "Grid_params = {\n",
    "    'feature_selection__k': [80, 100, 120, 130, 140],  # Number of top features to select\n",
    "    'classifier__var_smoothing': [1, 0.1, 0.01, 0.001]  # Smoothing parameter for Naive Bayes\n",
    "}\n",
    "\n",
    "# Perform grid search with 5-fold cross-validation and ROC AUC scoring\n",
    "grid_search = GridSearchCV(pipeline, param_grid=Grid_params, cv=StratifiedKFold(5), scoring='roc_auc', n_jobs=-1)\n",
    "grid_search.fit(X_Scaled, y)  # Fit the grid search to the scaled data and labels\n",
    "\n",
    "# Save the grid search results to a DataFrame\n",
    "results_df = pd.DataFrame(grid_search.cv_results_)\n",
    "\n",
    "# Export the results to an Excel file\n",
    "results_df.to_excel(\"grid_search_Naive_bayes_results_standard.xlsx\", index=False)\n",
    "\n",
    "# Print the best parameters found during grid search\n",
    "print(\"Beste parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5547c24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section performs a grid search to further optimize the hyperparameters of a Naive Bayes classifier.\n",
    "# The pipeline includes feature selection using SelectKBest and scaling using StandardScaler.\n",
    "# The grid search evaluates different numbers of selected features (`k`) and smoothing parameters (`var_smoothing`)\n",
    "# using 5-fold cross-validation with ROC AUC as the scoring metric.\n",
    "# The results are saved to an Excel file, and the best parameters are printed.\n",
    "\n",
    "# Laatste gridsearch\n",
    "scaler_standard = StandardScaler()  # Standardize features by removing the mean and scaling to unit variance\n",
    "X_Scaled = scaler_standard.fit_transform(X)  # Apply scaling to the feature set X\n",
    "\n",
    "gaussian = GaussianNB()  # Initialize Gaussian Naive Bayes classifier\n",
    "\n",
    "# Create a pipeline with feature selection and classifier\n",
    "pipeline = Pipeline([\n",
    "    ('feature_selection', SelectKBest()),  # Select top features (number of features determined by grid search)\n",
    "    ('classifier', gaussian)  # Use Gaussian Naive Bayes as the classifier\n",
    "])\n",
    "\n",
    "# Define grid search parameters for hyperparameter tuning\n",
    "Grid_params = {\n",
    "    'feature_selection__k': [124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135],  # Number of top features to select\n",
    "    'classifier__var_smoothing': [0.005, 0.006, 0.007, 0.008, 0.009, 0.01, 0.011, 0.012, 0.013, 0.014, 0.015, 0.016, 0.017]  # Smoothing parameter for Naive Bayes\n",
    "}\n",
    "\n",
    "# Perform grid search with 5-fold cross-validation and ROC AUC scoring\n",
    "grid_search = GridSearchCV(pipeline, param_grid=Grid_params, cv=StratifiedKFold(5), scoring='roc_auc', n_jobs=-1)\n",
    "grid_search.fit(X_Scaled, y)  # Fit the grid search to the scaled data and labels\n",
    "\n",
    "# Save the grid search results to a DataFrame\n",
    "results_df = pd.DataFrame(grid_search.cv_results_)\n",
    "\n",
    "# Export the results to an Excel file\n",
    "results_df.to_excel(\"grid_search_Naive_bayes_results_last.xlsx\", index=False)\n",
    "\n",
    "# Print the best parameters found during grid search\n",
    "print(\"Beste parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077dd37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section saves the final trained Naive Bayes model along with the selected features and scaler.\n",
    "# The final model is trained using the top 134 features selected by SelectKBest and a smoothing parameter of 0.011.\n",
    "# The trained model, selected features mask, and scaler saved as pickle files for future use.\n",
    "\n",
    "# Opslaan laatste model\n",
    "scaler_standard = StandardScaler()  # Standardize features by removing the mean and scaling to unit variance\n",
    "X_Scaled = scaler_standard.fit_transform(X)  # Apply scaling to the feature set X\n",
    "\n",
    "# Select the top 134 features using SelectKBest\n",
    "selector = SelectKBest(k=134)\n",
    "X_kbest = selector.fit_transform(X_Scaled, y)  # Apply feature selection\n",
    "selected_features_mask = selector.get_support()  # Get the mask of selected features\n",
    "\n",
    "# Train the Gaussian Naive Bayes classifier with the specified smoothing parameter\n",
    "gaussian = GaussianNB(var_smoothing=0.011)\n",
    "gaussian.fit(X_kbest, y)  # Fit the model to the selected features and labels\n",
    "\n",
    "# Save the trained model to a pickle file\n",
    "with open(r'BayesFinal\\naive_bayes_model.pkl', 'wb') as file:\n",
    "    pickle.dump(gaussian, file)\n",
    "\n",
    "# Save the selected features mask to a pickle file\n",
    "with open(r'BayesFinal\\selected_features_mask.pkl', 'wb') as file:\n",
    "    pickle.dump(selected_features_mask, file)\n",
    "\n",
    "# Save the scaler to a pickle file\n",
    "with open(r'BayesFinal\\naive_bayes_minmax_Scaler.pkl', 'wb') as file:\n",
    "    pickle.dump(scaler_standard, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fa80f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testcode\n",
    "\n",
    "clf = GaussianNB()\n",
    "\n",
    "\n",
    "\n",
    "scores = cross_validate(clf, X_Scaled, y, cv=StratifiedKFold(10), scoring=[\"roc_auc\", \"accuracy\"])\n",
    "print(f\"AUC = {scores['test_roc_auc'].mean()} and accuracy = {scores['test_accuracy'].mean()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
