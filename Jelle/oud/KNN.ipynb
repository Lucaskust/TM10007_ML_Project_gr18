{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:31: SyntaxWarning: invalid escape sequence '\\.'\n",
      "<>:31: SyntaxWarning: invalid escape sequence '\\.'\n",
      "C:\\Users\\jelle\\AppData\\Local\\Temp\\ipykernel_37380\\1585642262.py:31: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  data = pd.read_excel(\"..\\..\\TrainData.xlsx\")\n",
      "C:\\Users\\jelle\\AppData\\Local\\Temp\\ipykernel_37380\\1585642262.py:31: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  data = pd.read_excel(\"..\\..\\TrainData.xlsx\")\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '..\\\\..\\\\TrainData.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 31\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# 🧾 Stap 1 – Laad de data\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mTrainData.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# 🔍 Eerste inspectie\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVorm van de data:\u001b[39m\u001b[38;5;124m\"\u001b[39m, data\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[1;32mc:\\Users\\jelle\\OneDrive - Delft University of Technology\\10007 Machine learning\\.conda\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:495\u001b[0m, in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[0;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[0;32m    494\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 495\u001b[0m     io \u001b[38;5;241m=\u001b[39m ExcelFile(\n\u001b[0;32m    496\u001b[0m         io,\n\u001b[0;32m    497\u001b[0m         storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m    498\u001b[0m         engine\u001b[38;5;241m=\u001b[39mengine,\n\u001b[0;32m    499\u001b[0m         engine_kwargs\u001b[38;5;241m=\u001b[39mengine_kwargs,\n\u001b[0;32m    500\u001b[0m     )\n\u001b[0;32m    501\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[0;32m    502\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    503\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    504\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    505\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\jelle\\OneDrive - Delft University of Technology\\10007 Machine learning\\.conda\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1550\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m   1548\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxls\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1549\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1550\u001b[0m     ext \u001b[38;5;241m=\u001b[39m inspect_excel_format(\n\u001b[0;32m   1551\u001b[0m         content_or_path\u001b[38;5;241m=\u001b[39mpath_or_buffer, storage_options\u001b[38;5;241m=\u001b[39mstorage_options\n\u001b[0;32m   1552\u001b[0m     )\n\u001b[0;32m   1553\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1554\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1555\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExcel file format cannot be determined, you must specify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1556\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man engine manually.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1557\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\jelle\\OneDrive - Delft University of Technology\\10007 Machine learning\\.conda\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1402\u001b[0m, in \u001b[0;36minspect_excel_format\u001b[1;34m(content_or_path, storage_options)\u001b[0m\n\u001b[0;32m   1399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content_or_path, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[0;32m   1400\u001b[0m     content_or_path \u001b[38;5;241m=\u001b[39m BytesIO(content_or_path)\n\u001b[1;32m-> 1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[0;32m   1403\u001b[0m     content_or_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m, storage_options\u001b[38;5;241m=\u001b[39mstorage_options, is_text\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1404\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[0;32m   1405\u001b[0m     stream \u001b[38;5;241m=\u001b[39m handle\u001b[38;5;241m.\u001b[39mhandle\n\u001b[0;32m   1406\u001b[0m     stream\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\jelle\\OneDrive - Delft University of Technology\\10007 Machine learning\\.conda\\Lib\\site-packages\\pandas\\io\\common.py:882\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n\u001b[0;32m    883\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[0;32m    885\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '..\\\\..\\\\TrainData.xlsx'"
     ]
    }
   ],
   "source": [
    "# 📦 Vereiste imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Scikit-learn preprocessing, feature selection, and decomposition\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest, RFECV, SequentialFeatureSelector, f_classif\n",
    "\n",
    "# Scikit-learn models and evaluation\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import (\n",
    "    StratifiedKFold,\n",
    "    train_test_split,\n",
    "    cross_validate,\n",
    "    cross_val_score,\n",
    "    GridSearchCV,\n",
    ")\n",
    "from sklearn.metrics import accuracy_score, f1_score, make_scorer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "# Additional imports\n",
    "import pickle\n",
    "\n",
    "# 🧾 Stap 1 – Laad de data\n",
    "data = pd.read_excel(\"..\\..\\TrainData.xlsx\")\n",
    "\n",
    "# 🔍 Eerste inspectie\n",
    "print(\"Vorm van de data:\", data.shape)\n",
    "print(\"Kolommen:\", data.columns.tolist())\n",
    "print(\"Aantal duplicaten:\", data.duplicated().sum())\n",
    "print(\"Missende waarden per kolom:\")\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# 🧼 Stap 2 – Dubbele rijen verwijderen\n",
    "data = data.drop_duplicates()\n",
    "\n",
    "# 🎯 Stap 3 – Split in features en labels\n",
    "X = data.drop(columns=\"label\")\n",
    "y = data[\"label\"]\n",
    "\n",
    "# 🔁 Zet y om naar numeriek met behoud van pandas Series\n",
    "label_encoder = LabelEncoder()\n",
    "y = pd.Series(label_encoder.fit_transform(y), index=y.index)\n",
    "\n",
    "# ❓ Hoeveel missende waarden blijven over?\n",
    "print(\"Totaal aantal missende waarden:\", X.isnull().sum().sum())\n",
    "\n",
    "# ⚠️ Stap 4 – NaNs imputer (mediaan)\n",
    "X = X.fillna(X.median(numeric_only=True))\n",
    "\n",
    "\n",
    "#Data normalisatie\n",
    "\n",
    "X_Scaled = StandardScaler().fit_transform(X)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extra function to include RandomForest feature importance in KNN\n",
    "\n",
    "class KNNWithFeatureImportance(KNeighborsClassifier):\n",
    "    def __init__(self, n_neighbors=5, **kwargs):\n",
    "        super().__init__(n_neighbors=n_neighbors, **kwargs)\n",
    "        self.feature_importances_ = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # Call the original fit method\n",
    "        super().fit(X, y)\n",
    "        \n",
    "        # Create a simple feature importance based on feature variance\n",
    "        # This is just one possible approach - you could use other methods\n",
    "        rf_model = RandomForestClassifier(n_estimators=50)\n",
    "        rf_model.fit(X, y)\n",
    "        \n",
    "        self.feature_importances_ = rf_model.feature_importances_\n",
    "        \n",
    "        return self\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following code defines two pipelines for hyperparameter tuning using GridSearchCV.\n",
    "# Both pipelines aim to optimize the K-Nearest Neighbors (KNN) classifier with different feature selection methods.\n",
    "\n",
    "# Pipeline 1:\n",
    "# - Uses SelectKBest for univariate feature selection.\n",
    "# - Applies Recursive Feature Elimination with Cross-Validation (RFECV) to further refine feature selection.\n",
    "# - Reduces dimensionality using PCA.\n",
    "# - Trains the KNN classifier with a custom feature importance implementation (KNNWithFeatureImportance).\n",
    "# The hyperparameters for SelectKBest, PCA, and KNN are tuned using GridSearchCV.\n",
    "\n",
    "# Pipeline 2:\n",
    "# - Similar to Pipeline 1 but replaces RFECV with Sequential Feature Selector for feature selection.\n",
    "# - Trains a standard KNN classifier.\n",
    "# The hyperparameters for SelectKBest, PCA, and KNN are also tuned using GridSearchCV.\n",
    "\n",
    "# Both pipelines save their respective GridSearchCV results\n",
    "\n",
    "\n",
    "knnIMPORTANCE = KNNWithFeatureImportance()\n",
    "\n",
    "# Define the pipeline 1\n",
    "pipeline = Pipeline([\n",
    "    ('feature_selection_1', SelectKBest()), \n",
    "    ('feature_selection_2', RFECV(knnIMPORTANCE, step=1, cv=StratifiedKFold(5), scoring='roc_auc')),\n",
    "    ('pca', PCA()),  # PCA to reduce dimensionality\n",
    "    ('knn', knnIMPORTANCE)\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    \"feature_selection_1__k\": [80, 90, 100, 110, 120],\n",
    "    \"knn__n_neighbors\": [5, 7, 9, 11, 15, 20],\n",
    "    \"pca__n_components\": [10, 12, 14, 14+2, 18, 20, 0.9999]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=StratifiedKFold(5), scoring='roc_auc', n_jobs=-1)\n",
    "\n",
    "#new tested_score\n",
    "nested_score = cross_val_score(grid_search, X=, y=y_iris, cv=outer_cv)\n",
    "nested_scores[i] = nested_score.mean()\n",
    "\n",
    "\n",
    "grid_search.fit(X_Scaled, y)\n",
    "\n",
    "results_df = pd.DataFrame(grid_search.cv_results_)\n",
    "\n",
    "# Save the DataFrame to an Excel file\n",
    "results_df.to_excel(\"Results_grid_search\\grid_search_KNN_results_RFECV.xlsx\", index=False)\n",
    "\n",
    "#PIPELINE 2\n",
    "KNN = KNeighborsClassifier()\n",
    "\n",
    "pipeline_2 = Pipeline([\n",
    "    ('feature_selection_1', SelectKBest()), \n",
    "    ('feature_selection_2',SequentialFeatureSelector(KNN, direction='forward', scoring='roc_auc', n_jobs=-1)),\n",
    "    ('pca', PCA()),  # PCA to reduce dimensionality\n",
    "    ('knn', KNN)\n",
    "])\n",
    "\n",
    "param_grid_2 = {\n",
    "    \"feature_selection_1__k\": [80, 90, 100, 110, 120],\n",
    "    \"knn__n_neighbors\": [5, 7, 9, 11, 15, 20],\n",
    "    \"pca__n_components\": [10, 12, 14, 14+2, 18, 20, 0.9999]\n",
    "}\n",
    "\n",
    "grid_search_2 = GridSearchCV(pipeline_2, param_grid_2, cv=StratifiedKFold(5), scoring='roc_auc', n_jobs=-1)\n",
    "\n",
    "grid_search_2.fit(X_Scaled, y)\n",
    "\n",
    "results_df = pd.DataFrame(grid_search_2.cv_results_)\n",
    "\n",
    "# Save the DataFrame to an Excel file\n",
    "results_df.to_excel(\"Results_grid_search\\grid_search_KNN_results_forward.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code performs a final grid search to fine-tune the hyperparameters of the KNN classifier.\n",
    "# It uses a pipeline with the following steps:\n",
    "# - SelectKBest: Selects the top 80 features based on univariate statistical tests.\n",
    "# - RFECV: Applies Recursive Feature Elimination with Cross-Validation to further refine feature selection.\n",
    "# - PCA: Reduces the dimensionality of the data to 20 components.\n",
    "# - KNNWithFeatureImportance: A custom KNN classifier that incorporates feature importance.\n",
    "\n",
    "# The grid search optimizes the hyperparameters for SelectKBest, PCA, and KNN:\n",
    "# - \"feature_selection_1__k\": Number of features to select in SelectKBest.\n",
    "# - \"knn__n_neighbors\": Number of neighbors for the KNN classifier.\n",
    "# - \"pca__n_components\": Number of principal components to retain in PCA.\n",
    "\n",
    "# The results of the grid search are saved to an Excel file for further analysis.\n",
    "\n",
    "knnIMPORTANCE = KNNWithFeatureImportance()\n",
    "\n",
    "# Define the pipeline 1\n",
    "pipeline = Pipeline([\n",
    "    ('feature_selection_1', SelectKBest()), \n",
    "    ('feature_selection_2', RFECV(knnIMPORTANCE, step=1, cv=StratifiedKFold(5), scoring='roc_auc')),\n",
    "    ('pca', PCA()),  # PCA to reduce dimensionality\n",
    "    ('knn', knnIMPORTANCE)\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    \"feature_selection_1__k\": [50, 55, 60, 65, 70, 75, 80, 85],\n",
    "    \"knn__n_neighbors\": [3, 5],\n",
    "    \"pca__n_components\": [10, 12, 14, 16, 18, 20]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=StratifiedKFold(5), scoring='roc_auc', n_jobs=-2)\n",
    "\n",
    "grid_search.fit(X_Scaled, y)\n",
    "\n",
    "results_df = pd.DataFrame(grid_search.cv_results_)\n",
    "\n",
    "# Save the DataFrame to an Excel file\n",
    "results_df.to_excel(\"grid_search_KNN_results_RECV_2.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code defines a pipeline for further hyperparameter tuning of a KNN classifier with SequentialFeatureSelector:\n",
    "# - Step 1: SelectKBest selects the top 80 features based on univariate statistical tests.\n",
    "# - Step 2: SequentialFeatureSelector performs forward feature selection to refine the feature set.\n",
    "# - Step 3: PCA reduces the dimensionality of the data.\n",
    "# - Step 4: KNN classifier is trained on the processed features.\n",
    "# A GridSearchCV is used to optimize the hyperparameters for SelectKBest, SequentialFeatureSelector, PCA, and KNN.\n",
    "# The results of the grid search are saved to an Excel file for further analysis.\n",
    "\n",
    "\n",
    "\n",
    "KNN = KNeighborsClassifier()\n",
    "\n",
    "clf = SelectKBest(k=80)\n",
    "clf.fit(X_Scaled, y)\n",
    "X_k_best = clf.transform(X_Scaled)\n",
    "selected_features = clf.get_support(indices=True)\n",
    "\n",
    "\n",
    "pipeline_4 = Pipeline([\n",
    "  #  ('feature_selection_1', SelectKBest()), \n",
    "    ('feature_selection_2',SequentialFeatureSelector(KNN, direction='forward',cv=StratifiedKFold(5), scoring='roc_auc', n_jobs=-1)),\n",
    "  #  ('pca', PCA()),  # PCA to reduce dimensionality\n",
    "    ('knn', KNN)\n",
    "])\n",
    "\n",
    "param_grid_4 = {\n",
    "    #\"feature_selection_1__k\": [80],\n",
    "    'feature_selection_2__n_features_to_select': [2, 3, 4, 5, 6, 7, 8, 9],\n",
    "    \"knn__n_neighbors\": [5, 7, 9, 11, 15, 20],\n",
    "   # \"pca__n_components\": [0.9999]\n",
    "}\n",
    "\n",
    "grid_search_4 = GridSearchCV(pipeline_4, param_grid_4, cv=StratifiedKFold(5), scoring='roc_auc', n_jobs=-1)\n",
    "\n",
    "grid_search_4.fit(X_k_best, y)\n",
    "\n",
    "results_df = pd.DataFrame(grid_search_4.cv_results_)\n",
    "\n",
    "# Save the DataFrame to an Excel file\n",
    "results_df.to_excel(r\"Results_grid_search\\grid_search_KNN_results_forward_2.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jelle\\OneDrive - Delft University of Technology\\10007 Machine learning\\.conda\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:111: UserWarning: Features [ 76  77  83  84  85  90  96  97 103 109 110 467 474 475 480 487 488] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\jelle\\OneDrive - Delft University of Technology\\10007 Machine learning\\.conda\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n"
     ]
    }
   ],
   "source": [
    "# Save the final trained KNN model along with feature masks and scaler\n",
    "\n",
    "# Step 1: Standardize the features using StandardScaler\n",
    "scaler_standard = StandardScaler()\n",
    "X_Scaled = scaler_standard.fit_transform(X)\n",
    "\n",
    "# Step 2: Perform feature selection using SelectKBest\n",
    "selector_KBest = SelectKBest(k=80)  # Select the top 80 features\n",
    "X_kbest = selector_KBest.fit_transform(X_Scaled, y)\n",
    "X_kbest_features_mask = selector_KBest.get_support()  # Boolean mask of selected features\n",
    "\n",
    "# Step 3: Initialize the custom KNN classifier with feature importance\n",
    "#KNN = KNNWithFeatureImportance(n_neighbors=5)\n",
    "KNN = KNeighborsClassifier(n_neighbors=9)\n",
    "\n",
    "# Step 4: Perform Recursive Feature Elimination with Cross-Validation (RFECV)\n",
    "#selector_RFECV = RFECV(KNN, step=1, cv=StratifiedKFold(5), scoring='roc_auc')\n",
    "#X_selected = selector_RFECV.fit_transform(X_kbest, y)\n",
    "#X_RFECV_features_mask = selector_RFECV.get_support()  # Boolean mask of selected features after RFECV\n",
    "selector_forward = SequentialFeatureSelector(KNN, n_features_to_select= 9, direction='forward', cv=StratifiedKFold(5), scoring='roc_auc', n_jobs=-1)\n",
    "X_selected = selector_forward.fit_transform(X_kbest, y)\n",
    "X_forward_features_mask = selector_forward.get_support()  # Boolean mask of selected features after RFECV\n",
    "\n",
    "# Step 5: Combine the feature masks from SelectKBest and selector\n",
    "X_features_mask_total = np.zeros(len(X_kbest_features_mask), dtype=bool)  # Initialize a mask with all False\n",
    "indices_after_X_kbest_features_mask = np.where(X_kbest_features_mask)[0]  # Indices of features selected by SelectKBest\n",
    "indices_to_keep = indices_after_X_kbest_features_mask[X_forward_features_mask]  # Apply  mask to SelectKBest features\n",
    "X_features_mask_total[indices_to_keep] = True  # Update the combined mask\n",
    "\n",
    "# Step 6: Train the final KNN model on the selected features\n",
    "KNN.fit(X_selected, y)\n",
    "\n",
    "# Step 7: Save the trained KNN model, combined feature mask, and scaler to disk\n",
    "with open(r'KNNFinal\\KNN_model.pkl', 'wb') as file:\n",
    "    pickle.dump(KNN, file)  # Save the trained KNN model\n",
    "\n",
    "with open(r'KNNFinal\\selected_features_mask.pkl', 'wb') as file:\n",
    "    pickle.dump(X_features_mask_total, file)  # Save the combined feature mask\n",
    "\n",
    "with open(r'KNNFinal\\KNN_Scaler.pkl', 'wb') as file:\n",
    "    pickle.dump(scaler_standard, file)  # Save the scaler used for standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The following code was used to try different things and plot the graphs\n",
    "\n",
    "#k-best\n",
    "clf = SelectKBest(k=120)\n",
    "clf.fit(X_Scaled, y)\n",
    "X_k_best = clf.transform(X_Scaled)\n",
    "selected_features = clf.get_support(indices=True)\n",
    "\n",
    "#RFECV met KNN\n",
    "clf = KNNWithFeatureImportance(n_neighbors=5)\n",
    "selector = RFECV(clf, step=1, cv=StratifiedKFold(5), scoring='accuracy')\n",
    "X_selected = selector.fit_transform(X_k_best, y)\n",
    "\n",
    "\n",
    "# make a plot of the KNNWithFeatureImportance\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross-validation score (ROC AUC)\")\n",
    "plt.title(\"Recursive Feature Elimination with Cross-Validation (KNN=5)\")\n",
    "plt.grid(True)\n",
    "plt.plot(range(1, len(selector.cv_results_['mean_test_score']) + 1), selector.cv_results_['mean_test_score'])\n",
    "plt.show()\n",
    "\n",
    "#SequentialFeatureSelector\n",
    "clf = KNeighborsClassifier(n_neighbors=9)\n",
    "selector = SequentialFeatureSelector(clf, direction='forward', cv=StratifiedKFold(5))\n",
    "X_selected = selector.fit_transform(X_k_best, y)\n",
    "\n",
    "# make a plot of the KNNWithFeatureImportance\n",
    "cv = StratifiedKFold(5)\n",
    "scores = []\n",
    "for n_features in range(1, X_k_best.shape[1] + 1):\n",
    "    selector = SequentialFeatureSelector(clf, n_features_to_select=n_features, direction='forward', cv=cv)\n",
    "    X_selected = selector.fit_transform(X_k_best, y)\n",
    "    score = np.mean(cross_val_score(clf, X_selected, y, cv=cv, scoring='roc_auc'))\n",
    "    scores.append(score)\n",
    "\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross-validation score (ROC AUC)\")\n",
    "plt.title(\"Forward Feature Elimination with Cross-Validation (KNN=9)\")\n",
    "plt.grid(True)\n",
    "plt.plot(range(1, len(scores) + 1), scores)\n",
    "plt.show()\n",
    "\n",
    "#general testcode\n",
    "KNN = KNeighborsClassifier(n_neighbors=4+1)\n",
    "scores = cross_validate(KNN, X_selected, y, cv=StratifiedKFold(10), scoring=[\"roc_auc\", \"accuracy\"])\n",
    "print(f\"AUC = {scores['test_roc_auc'].mean()} and accuracy = {scores['test_accuracy'].mean()}\")\n",
    "\n",
    "\n",
    "# using PCA to reduce the dimensionality of the data\n",
    "from sklearn.decomposition import PCA\n",
    "for i in [22]:\n",
    "    pca = PCA(n_components=i) \n",
    "    X_pca = pca.fit_transform(X_selected)\n",
    "    KNN = KNeighborsClassifier(n_neighbors=4+1)\n",
    "    scores = cross_validate(KNN, X_pca, y, cv=StratifiedKFold(10), scoring=[\"roc_auc\", \"accuracy\"])\n",
    "    print(f\"AUC = {scores['test_roc_auc'].mean()} and accuracy = {scores['test_accuracy'].mean()}\")\n",
    "\n",
    "\n",
    "# baseline test\n",
    "scores = cross_validate(KNN, X, y, cv=StratifiedKFold(10), scoring=[\"roc_auc\", \"accuracy\"])\n",
    "print(f\"AUC = {scores['test_roc_auc'].mean()} and accuracy = {scores['test_accuracy'].mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_k_best.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jelle\\OneDrive - Delft University of Technology\\10007 Machine learning\\.conda\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:111: UserWarning: Features [ 76  77  83  84  85  90  96  97 103 109 110 467 474 475 480 487 488] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\jelle\\OneDrive - Delft University of Technology\\10007 Machine learning\\.conda\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n"
     ]
    }
   ],
   "source": [
    "#k-best\n",
    "clf = SelectKBest(k=80)\n",
    "clf.fit(X_Scaled, y)\n",
    "X_k_best = clf.transform(X_Scaled)\n",
    "selected_features = clf.get_support(indices=True)\n",
    "\n",
    "\n",
    "KNN = KNeighborsClassifier(n_neighbors=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.8478806907378335)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = StratifiedKFold(5)\n",
    "\n",
    "selector = SequentialFeatureSelector(KNN, n_features_to_select=9, direction='forward', cv=cv, n_jobs=-1)\n",
    "X_selected = selector.fit_transform(X_k_best, y)\n",
    "np.mean(cross_val_score(KNN, X_selected, y, cv=cv, scoring='roc_auc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.8552197802197803)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=0.99) \n",
    "X_pca = pca.fit_transform(X_selected)\n",
    "\n",
    "\n",
    "np.mean(cross_val_score(KNN, X_pca, y, cv=cv, scoring='roc_auc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a plot of the SequentialFeatureSelector\n",
    "\n",
    "cv = StratifiedKFold(5)\n",
    "scores = []\n",
    "for n_features in range(1, X_k_best.shape[1] + 1):\n",
    "    selector = SequentialFeatureSelector(KNN, n_features_to_select=n_features, direction='forward', cv=cv, n_jobs=-1)\n",
    "    X_selected = selector.fit_transform(X_k_best, y)\n",
    "    score = np.mean(cross_val_score(KNN, X_selected, y, cv=cv, scoring='roc_auc'))\n",
    "    scores.append(score)\n",
    "    print(score)\n",
    "\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross-validation score (ROC AUC)\")\n",
    "plt.title(\"Forward Feature Elimination with Cross-Validation (KNN=9)\")\n",
    "plt.grid(True)\n",
    "plt.plot(range(1, len(scores) + 1), scores)\n",
    "plt.savefig(r\"pictures\\KNN_SequentialFeatureSelector.png\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
